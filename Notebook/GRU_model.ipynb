{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu de donnÃ©es initial \n",
    "train = pd.read_json(\"train.json\", lines = True)\n",
    "test = pd.read_json(\"test.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import plotly.express as px\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.random.normal((32, 68, 3))\n",
    "y_pred = tf.random.normal((32, 68, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    re = tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    print(re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.GRU(\n",
    "        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))\n",
    "\n",
    "def build_model(embed_size, seq_len=107, pred_len=68, dropout=0.5, \n",
    "                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=2):\n",
    "    inputs = L.Input(shape=(seq_len, 4))# 107 longueur sequence - 4 ATGU\n",
    "    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n",
    "    \n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n",
    "    \n",
    "    for x in range(n_layers):\n",
    "        print(x,\"layer\")\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    # Since we are only making predictions on the first part of each sequence, \n",
    "    # we have to truncate it\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    out = L.Dense(5, activation='linear')(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    model.compile(tf.optimizers.Adam(), loss=MCRMSE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return pandas_list_to_array(\n",
    "        df[cols].applymap(lambda seq: [token2int[x] for x in seq])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"signal_to_noise >= 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "train_inputs = preprocess_inputs(train, token2int)\n",
    "train_labels = pandas_list_to_array(train[pred_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1887, 107, 3)\n",
      "(1887, 68, 5)\n",
      "(1887, 68, 4)\n",
      "(1887, 68, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_inputs, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_seq, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 0, 1]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]]]),\n",
       "       list([[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]]]),\n",
       "       list([[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]]]),\n",
       "       ...,\n",
       "       list([[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]]]),\n",
       "       list([[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]]]),\n",
       "       list([[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 1, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 0, 1]], [[0, 0, 1, 0]], [[0, 1, 0, 0]], [[0, 0, 1, 0]], [[0, 0, 0, 1]], [[0, 1, 0, 0]], [[1, 0, 0, 0]], [[0, 0, 1, 0]]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first68_train['One_hot seq'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = test.query(\"seq_length == 107\")\n",
    "private_df = test.query(\"seq_length == 130\")\n",
    "\n",
    "public_inputs = preprocess_inputs(public_df, token2int)\n",
    "private_inputs = preprocess_inputs(private_df, token2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1887, 68, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 layer\n",
      "1 layer\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 107, 4)]          0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 107, 4, 200)       2800      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(None, 107, 800)]        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 107, 800)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 107, 512)          1625088   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 107, 512)          1182720   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 68, 512)]         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 68, 5)             2565      \n",
      "=================================================================\n",
      "Total params: 2,813,173\n",
      "Trainable params: 2,813,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(embed_size=len(token2int))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 107, 4) for input Tensor(\"input_1:0\", shape=(None, 107, 4), dtype=float32), but it was called on an input with incompatible shape (None, 68, 4).\n",
      "Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 107, 4) for input Tensor(\"input_1:0\", shape=(None, 107, 4), dtype=float32), but it was called on an input with incompatible shape (None, 68, 4).\n",
      "Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input to reshape is a tensor with 1305600 values, but the requested shape requires a multiple of 85600\n\t [[node functional_1/tf_op_layer_Reshape/Reshape (defined at <ipython-input-35-f562f9af4156>:1) ]] [Op:__inference_train_function_11358]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f562f9af4156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 1305600 values, but the requested shape requires a multiple of 85600\n\t [[node functional_1/tf_op_layer_Reshape/Reshape (defined at <ipython-input-35-f562f9af4156>:1) ]] [Op:__inference_train_function_11358]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=24,\n",
    "    epochs=1,\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n",
    "        tf.keras.callbacks.ModelCheckpoint('model.h5')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.25233644859813"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1305600/85600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    history.history, y=['loss', 'val_loss'],\n",
    "    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n",
    "    title='Training History')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.GRU(\n",
    "        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))\n",
    "\n",
    "def build_model(embed_size, seq_len=68, pred_len=68, dropout=0.5, \n",
    "                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=2):\n",
    "    inputs = L.Input(shape=(seq_len, 1))# 68 longueur sequence - 3 seq/strct/loop\n",
    "    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n",
    "    \n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n",
    "    \n",
    "    for x in range(n_layers):\n",
    "        print(x,\"layer\")\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    # Since we are only making predictions on the first part of each sequence, \n",
    "    # we have to truncate it\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    out = L.Dense(5, activation='linear')(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    model.compile(tf.optimizers.Adam(), loss=MCRMSE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_set(df, list_column):\n",
    "    \"\"\"\n",
    "    Fonction qui crÃ©e d'une fenetre de lecture de 68 bases. \n",
    "        :Parameters:\n",
    "            df = un data frame train\n",
    "            list_column = numero de la colonne du data frame \n",
    "        :Return:\n",
    "            deux data frame :\n",
    "                first68_train = data frame contenant les 68 premieres bases et annotations de structure\n",
    "                last68_train = data frame contenant les 68 dernieres bases et annotations de structure\n",
    "    \"\"\"\n",
    "    first68 = df.copy()\n",
    "    last68 = df.copy()\n",
    "    for a in list_column :\n",
    "        for i, r in enumerate(df.iloc[:,a]):\n",
    "            first68.iloc[i,a] = r[0:68]\n",
    "            last68.iloc[i,a] = r[len(r)-68:]\n",
    "    return first68, last68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first68_train, last68_train = divide_set(train, [2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>...</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>One_hot seq</th>\n",
       "      <th>One hot strucure</th>\n",
       "      <th>encoding predicted loop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>id_00ab2d761</td>\n",
       "      <td>GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...</td>\n",
       "      <td>.....(.(((((.(((((((((...........)))))))..(((....</td>\n",
       "      <td>EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...</td>\n",
       "      <td>4.136</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.165, 0.20520000000000002, 0.179, 0.1333, 0....</td>\n",
       "      <td>[0.2864, 0.24710000000000001, 0.2222, 0.1903, ...</td>\n",
       "      <td>[0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...</td>\n",
       "      <td>[0.9559000000000001, 1.9442, 1.0114, 0.5105000...</td>\n",
       "      <td>[1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...</td>\n",
       "      <td>[0.22460000000000002, 1.7281, 1.381, 0.6623, 0...</td>\n",
       "      <td>[0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>id_00abef1d7</td>\n",
       "      <td>GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...</td>\n",
       "      <td>.........((((((((......((((((((((((....)))))))...</td>\n",
       "      <td>EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>2.485</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.422, 0.5478000000000001, 0.4749000000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...</td>\n",
       "      <td>[0.9306000000000001, 1.0496, 0.5844, 0.7796000...</td>\n",
       "      <td>[0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...</td>\n",
       "      <td>[0.46040000000000003, 3.6695, 0.78550000000000...</td>\n",
       "      <td>[2.7711, 7.365, 1.6924000000000001, 1.43840000...</td>\n",
       "      <td>[1.073, 2.8604000000000003, 1.9936, 1.0273, 1....</td>\n",
       "      <td>[2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>id_00b436dec</td>\n",
       "      <td>GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...</td>\n",
       "      <td>.....(((((((((((..(((((((((..((((....))))..)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...</td>\n",
       "      <td>1.727</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.4843, 0.5233, 0.4554, 0.43520000000000003, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.384, 0.723, 0.4766, 0.30260000000000004, 0....</td>\n",
       "      <td>[0.7429, 0.9137000000000001, 0.480400000000000...</td>\n",
       "      <td>[1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...</td>\n",
       "      <td>[1.6912, 5.2652, 2.3901, 0.45890000000000003, ...</td>\n",
       "      <td>[1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...</td>\n",
       "      <td>[0.49060000000000004, 4.6339, 1.95860000000000...</td>\n",
       "      <td>[1.2852000000000001, 2.5460000000000003, 0.234...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2394</td>\n",
       "      <td>id_ff13729b0</td>\n",
       "      <td>GGAAAUAAAUAAAUAACAAUAAAGAGAUAAGACACAAUAAAUAAAA...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...</td>\n",
       "      <td>1.995</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.3019, 0.33680000000000004, 0.25980000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25930000000000003, 0.3074, 0.2109, 0.1995, ...</td>\n",
       "      <td>[0.465, 0.6078, 0.30310000000000004, 0.3873000...</td>\n",
       "      <td>[0.3517, 0.5358, 0.4318, 0.016900000000000002,...</td>\n",
       "      <td>[0.6612, 1.0221, 0.1676, 0.1648, 0.5634, 0.645...</td>\n",
       "      <td>[4.0973, 2.0778, 0.2776, 0.1207, 0.63140000000...</td>\n",
       "      <td>[0.2661, 0.5771000000000001, 0.3517, 0.295, 0....</td>\n",
       "      <td>[0.2897, 1.1666, 0.135, 0.4742, 0.9522, 0.8408...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2395</td>\n",
       "      <td>id_ff84602f7</td>\n",
       "      <td>GGAAAAUAGCAGAGGAAAUACUAGAGCAAUUGCAAAGGCCGAUCAU...</td>\n",
       "      <td>........((..((......))...)).........(((..........</td>\n",
       "      <td>EEEEEEEESSIISSHHHHHHSSIIISSXXXXXXXXXSSSHHHHHHH...</td>\n",
       "      <td>4.036</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2585, 0.29710000000000003, 0.2748, 0.205000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2093, 0.2985, 0.2922, 0.08360000000000001, ...</td>\n",
       "      <td>[0.29460000000000003, 0.40850000000000003, 0.3...</td>\n",
       "      <td>[0.6957, 1.251, 1.3235999999999999, 0.7521, 0....</td>\n",
       "      <td>[0.6439, 2.0117, 1.3682, 0.0918, 0.65860000000...</td>\n",
       "      <td>[2.1589, 3.3601, 1.6179000000000001, 0.1344000...</td>\n",
       "      <td>[0.47900000000000004, 1.9583, 2.4635, 0.0512, ...</td>\n",
       "      <td>[0.5759000000000001, 2.3736, 1.4158, 0.1914000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2396</td>\n",
       "      <td>id_ff85fcdba</td>\n",
       "      <td>GGAAAACAAAAACAAACAACAAAAACAAACAACAAAAACAAACAAC...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...</td>\n",
       "      <td>3.227</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2169, 0.2513, 0.2303, 0.22260000000000002, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2758, 0.3659, 0.2155, 0.28340000000000004, ...</td>\n",
       "      <td>[0.401, 0.388, 0.3403, 0.3608, 0.3057, 0.242, ...</td>\n",
       "      <td>[0.2891, 0.4496, 0.7165, 0.7128, 0.59310000000...</td>\n",
       "      <td>[0.3619, 0.6924, 0.2988, 0.3639, 0.545, 0.2263...</td>\n",
       "      <td>[2.8541, 1.6106, 1.4343, 1.0797, 0.6803, 0.559...</td>\n",
       "      <td>[0.2964, 0.9351, 0.2555, 0.7603000000000001, 0...</td>\n",
       "      <td>[0.6526000000000001, 0.2548, 0.6927, 0.9316000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>id_ffe06f3fe</td>\n",
       "      <td>GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...</td>\n",
       "      <td>.....((((..(....)..))))......(((....)))..........</td>\n",
       "      <td>EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...</td>\n",
       "      <td>5.553</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1431, 0.1847, 0.15960000000000002, 0.1466, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0944, 0.1453, 0.1067, 0.0994, 0.06470000000...</td>\n",
       "      <td>[0.1691, 0.22740000000000002, 0.178, 0.1762, 0...</td>\n",
       "      <td>[0.6919000000000001, 1.4823, 1.3685, 1.2473, 0...</td>\n",
       "      <td>[0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...</td>\n",
       "      <td>[2.7157999999999998, 3.1249000000000002, 1.137...</td>\n",
       "      <td>[0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...</td>\n",
       "      <td>[0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>id_fff546103</td>\n",
       "      <td>GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...</td>\n",
       "      <td>.....((((((((((((((((...)))).)))).((((((((((.....</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...</td>\n",
       "      <td>6.545</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1782, 0.2043, 0.1842, 0.13240000000000002, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.22060000000000002, 0.254, 0.2109, 0.1636, 0...</td>\n",
       "      <td>[0.2379, 0.27590000000000003, 0.22160000000000...</td>\n",
       "      <td>[1.0102, 1.7928000000000002, 1.9228, 0.9649000...</td>\n",
       "      <td>[1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...</td>\n",
       "      <td>[2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...</td>\n",
       "      <td>[1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...</td>\n",
       "      <td>[0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2097 rows Ã 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index            id                                           sequence  \\\n",
       "0         0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "2         2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "5         5  id_00ab2d761  GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...   \n",
       "6         6  id_00abef1d7  GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...   \n",
       "7         7  id_00b436dec  GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...   \n",
       "...     ...           ...                                                ...   \n",
       "2394   2394  id_ff13729b0  GGAAAUAAAUAAAUAACAAUAAAGAGAUAAGACACAAUAAAUAAAA...   \n",
       "2395   2395  id_ff84602f7  GGAAAAUAGCAGAGGAAAUACUAGAGCAAUUGCAAAGGCCGAUCAU...   \n",
       "2396   2396  id_ff85fcdba  GGAAAACAAAAACAAACAACAAAAACAAACAACAAAAACAAACAAC...   \n",
       "2398   2398  id_ffe06f3fe  GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...   \n",
       "2399   2399  id_fff546103  GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...   \n",
       "\n",
       "                                              structure  \\\n",
       "0     .....((((((.......)))).)).((.....((..((((((......   \n",
       "2     .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "5     .....(.(((((.(((((((((...........)))))))..(((....   \n",
       "6     .........((((((((......((((((((((((....)))))))...   \n",
       "7     .....(((((((((((..(((((((((..((((....))))..)))...   \n",
       "...                                                 ...   \n",
       "2394  .................................................   \n",
       "2395  ........((..((......))...)).........(((..........   \n",
       "2396  .................................................   \n",
       "2398  .....((((..(....)..))))......(((....)))..........   \n",
       "2399  .....((((((((((((((((...)))).)))).((((((((((.....   \n",
       "\n",
       "                                    predicted_loop_type  signal_to_noise  \\\n",
       "0     EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "2     EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "5     EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...            4.136   \n",
       "6     EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...            2.485   \n",
       "7     EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...            1.727   \n",
       "...                                                 ...              ...   \n",
       "2394  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...            1.995   \n",
       "2395  EEEEEEEESSIISSHHHHHHSSIIISSXXXXXXXXXSSSHHHHHHH...            4.036   \n",
       "2396  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...            3.227   \n",
       "2398  EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...            5.553   \n",
       "2399  EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...            6.545   \n",
       "\n",
       "      SN_filter  seq_length  seq_scored  \\\n",
       "0             1         107          68   \n",
       "2             1         107          68   \n",
       "5             1         107          68   \n",
       "6             1         107          68   \n",
       "7             1         107          68   \n",
       "...         ...         ...         ...   \n",
       "2394          0         107          68   \n",
       "2395          1         107          68   \n",
       "2396          1         107          68   \n",
       "2398          0         107          68   \n",
       "2399          1         107          68   \n",
       "\n",
       "                                       reactivity_error  ...  \\\n",
       "0     [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  ...   \n",
       "2     [0.0931, 0.13290000000000002, 0.11280000000000...  ...   \n",
       "5     [0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...  ...   \n",
       "6     [0.422, 0.5478000000000001, 0.4749000000000000...  ...   \n",
       "7     [0.4843, 0.5233, 0.4554, 0.43520000000000003, ...  ...   \n",
       "...                                                 ...  ...   \n",
       "2394  [0.3019, 0.33680000000000004, 0.25980000000000...  ...   \n",
       "2395  [0.2585, 0.29710000000000003, 0.2748, 0.205000...  ...   \n",
       "2396  [0.2169, 0.2513, 0.2303, 0.22260000000000002, ...  ...   \n",
       "2398  [0.1431, 0.1847, 0.15960000000000002, 0.1466, ...  ...   \n",
       "2399  [0.1782, 0.2043, 0.1842, 0.13240000000000002, ...  ...   \n",
       "\n",
       "                                       deg_error_Mg_50C  \\\n",
       "0     [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "2     [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "5     [0.165, 0.20520000000000002, 0.179, 0.1333, 0....   \n",
       "6     [0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...   \n",
       "7     [0.384, 0.723, 0.4766, 0.30260000000000004, 0....   \n",
       "...                                                 ...   \n",
       "2394  [0.25930000000000003, 0.3074, 0.2109, 0.1995, ...   \n",
       "2395  [0.2093, 0.2985, 0.2922, 0.08360000000000001, ...   \n",
       "2396  [0.2758, 0.3659, 0.2155, 0.28340000000000004, ...   \n",
       "2398  [0.0944, 0.1453, 0.1067, 0.0994, 0.06470000000...   \n",
       "2399  [0.22060000000000002, 0.254, 0.2109, 0.1636, 0...   \n",
       "\n",
       "                                          deg_error_50C  \\\n",
       "0     [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "2     [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "5     [0.2864, 0.24710000000000001, 0.2222, 0.1903, ...   \n",
       "6     [0.9306000000000001, 1.0496, 0.5844, 0.7796000...   \n",
       "7     [0.7429, 0.9137000000000001, 0.480400000000000...   \n",
       "...                                                 ...   \n",
       "2394  [0.465, 0.6078, 0.30310000000000004, 0.3873000...   \n",
       "2395  [0.29460000000000003, 0.40850000000000003, 0.3...   \n",
       "2396  [0.401, 0.388, 0.3403, 0.3608, 0.3057, 0.242, ...   \n",
       "2398  [0.1691, 0.22740000000000002, 0.178, 0.1762, 0...   \n",
       "2399  [0.2379, 0.27590000000000003, 0.22160000000000...   \n",
       "\n",
       "                                             reactivity  \\\n",
       "0     [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "2     [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "5     [0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...   \n",
       "6     [0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...   \n",
       "7     [1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...   \n",
       "...                                                 ...   \n",
       "2394  [0.3517, 0.5358, 0.4318, 0.016900000000000002,...   \n",
       "2395  [0.6957, 1.251, 1.3235999999999999, 0.7521, 0....   \n",
       "2396  [0.2891, 0.4496, 0.7165, 0.7128, 0.59310000000...   \n",
       "2398  [0.6919000000000001, 1.4823, 1.3685, 1.2473, 0...   \n",
       "2399  [1.0102, 1.7928000000000002, 1.9228, 0.9649000...   \n",
       "\n",
       "                                            deg_Mg_pH10  \\\n",
       "0     [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "2     [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "5     [0.9559000000000001, 1.9442, 1.0114, 0.5105000...   \n",
       "6     [0.46040000000000003, 3.6695, 0.78550000000000...   \n",
       "7     [1.6912, 5.2652, 2.3901, 0.45890000000000003, ...   \n",
       "...                                                 ...   \n",
       "2394  [0.6612, 1.0221, 0.1676, 0.1648, 0.5634, 0.645...   \n",
       "2395  [0.6439, 2.0117, 1.3682, 0.0918, 0.65860000000...   \n",
       "2396  [0.3619, 0.6924, 0.2988, 0.3639, 0.545, 0.2263...   \n",
       "2398  [0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...   \n",
       "2399  [1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...   \n",
       "\n",
       "                                               deg_pH10  \\\n",
       "0     [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "2     [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "5     [1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...   \n",
       "6     [2.7711, 7.365, 1.6924000000000001, 1.43840000...   \n",
       "7     [1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...   \n",
       "...                                                 ...   \n",
       "2394  [4.0973, 2.0778, 0.2776, 0.1207, 0.63140000000...   \n",
       "2395  [2.1589, 3.3601, 1.6179000000000001, 0.1344000...   \n",
       "2396  [2.8541, 1.6106, 1.4343, 1.0797, 0.6803, 0.559...   \n",
       "2398  [2.7157999999999998, 3.1249000000000002, 1.137...   \n",
       "2399  [2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...   \n",
       "\n",
       "                                             deg_Mg_50C  \\\n",
       "0     [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "2     [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "5     [0.22460000000000002, 1.7281, 1.381, 0.6623, 0...   \n",
       "6     [1.073, 2.8604000000000003, 1.9936, 1.0273, 1....   \n",
       "7     [0.49060000000000004, 4.6339, 1.95860000000000...   \n",
       "...                                                 ...   \n",
       "2394  [0.2661, 0.5771000000000001, 0.3517, 0.295, 0....   \n",
       "2395  [0.47900000000000004, 1.9583, 2.4635, 0.0512, ...   \n",
       "2396  [0.2964, 0.9351, 0.2555, 0.7603000000000001, 0...   \n",
       "2398  [0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...   \n",
       "2399  [1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...   \n",
       "\n",
       "                                                deg_50C  \\\n",
       "0     [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...   \n",
       "2     [0.9501000000000001, 1.7974999999999999, 1.499...   \n",
       "5     [0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...   \n",
       "6     [2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...   \n",
       "7     [1.2852000000000001, 2.5460000000000003, 0.234...   \n",
       "...                                                 ...   \n",
       "2394  [0.2897, 1.1666, 0.135, 0.4742, 0.9522, 0.8408...   \n",
       "2395  [0.5759000000000001, 2.3736, 1.4158, 0.1914000...   \n",
       "2396  [0.6526000000000001, 0.2548, 0.6927, 0.9316000...   \n",
       "2398  [0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...   \n",
       "2399  [0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...   \n",
       "\n",
       "                                            One_hot seq  \\\n",
       "0     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "5     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "6     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "7     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "...                                                 ...   \n",
       "2394  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2395  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2396  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2398  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2399  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "\n",
       "                                       One hot strucure  \\\n",
       "0     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "5     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "6     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "7     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "...                                                 ...   \n",
       "2394  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2395  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2396  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2398  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2399  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "\n",
       "                                encoding predicted loop  \n",
       "0     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "5     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "6     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "7     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2394  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2395  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2396  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2398  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2399  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2097 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encoding(df, name_colonne):\n",
    "    \"\"\"\n",
    "    Fonction pour encoder les sequences, structures et type boucles : One hot encoding\n",
    "        :Parameters:\n",
    "            df = data frame : train et test de dÃ©part\n",
    "            name_colonne = le nom de la colonne du df \n",
    "        :Return:\n",
    "            un tableau\n",
    "    \"\"\"\n",
    "    frst_lst = []\n",
    "    for r in df[name_colonne]:\n",
    "        for i in range(len(r)):\n",
    "            if r[i] not in frst_lst:\n",
    "                frst_lst.append(r[i])\n",
    "    dico = {}\n",
    "    ar = np.zeros(shape=(1,len(frst_lst)),dtype=int)\n",
    "    for i, l in enumerate(frst_lst):\n",
    "        ar2 = ar.copy()\n",
    "        ar2[0][i]=1\n",
    "        dico[l]=ar2\n",
    "    scnd_lst = []\n",
    "    for r in df[name_colonne]:\n",
    "        lst = [] \n",
    "        for i in range(len(r)):\n",
    "            #print(dico[r[i]], r[i])\n",
    "            lst.append(dico[r[i]])\n",
    "        scnd_lst.append(lst)\n",
    "    return np.array(scnd_lst)\n",
    "\n",
    "tab = one_hot_encoding(first68_train, 'sequence')\n",
    "tab2 = one_hot_encoding(first68_train, 'structure')\n",
    "tab3 = one_hot_encoding(first68_train, 'predicted_loop_type')\n",
    "\n",
    "first68_train[\"One_hot seq\"] = tab.tolist() # ajout des colonnes encoding a notre DF de dÃ©part\n",
    "first68_train[\"One hot strucure\"] = tab2.tolist()\n",
    "first68_train[\"encoding predicted loop\"] = tab3.tolist()\n",
    "first68_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_format(df, colname):\n",
    "    \"\"\"\n",
    "    juste pck j'crois que y'avait des liste dans des listes\n",
    "    j'ai transformÃ© en liste d'array\n",
    "    \"\"\"\n",
    "    x1 = df[colname].copy()\n",
    "    x2 = []\n",
    "    for r in x1:\n",
    "        lst = []\n",
    "        for u in r:\n",
    "            lst.append(np.array(u[0], float))\n",
    "        lst = np.array(lst)\n",
    "        x2.append(lst)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = right_format(first68_train, \"One_hot seq\")\n",
    "#x_strct = right_format(first68_train, \"One hot strucure\")\n",
    "#x_loop = right_format(first68_train, \"encoding predicted loop\")\n",
    "\n",
    "#print(len(x_seq))\n",
    "#print(len(x_strct))\n",
    "#print(len(x_loop))\n",
    "x_seq = np.array(x_seq)\n",
    "x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = first68_train['reactivity'].values\n",
    "y2 = first68_train['deg_Mg_pH10'].values\n",
    "y3 = first68_train['deg_Mg_50C'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1887, 107, 3), dtype=int64, numpy=\n",
       "array([[[5, 2, 8],\n",
       "        [5, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        ...,\n",
       "        [3, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        [4, 2, 8]],\n",
       "\n",
       "       [[5, 2, 8],\n",
       "        [5, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        ...,\n",
       "        [3, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        [4, 2, 8]],\n",
       "\n",
       "       [[5, 2, 8],\n",
       "        [5, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        ...,\n",
       "        [3, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        [4, 2, 8]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[5, 2, 8],\n",
       "        [5, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        ...,\n",
       "        [3, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        [4, 2, 8]],\n",
       "\n",
       "       [[5, 2, 8],\n",
       "        [5, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        ...,\n",
       "        [3, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        [4, 2, 8]],\n",
       "\n",
       "       [[5, 2, 8],\n",
       "        [5, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        ...,\n",
       "        [3, 2, 8],\n",
       "        [3, 2, 8],\n",
       "        [4, 2, 8]]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tf.convert_to_tensor(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0.3297, 1.5693000000000001, 1.1227, 0.8686, 0.7217, 0.4384, 0.256, 0.33640000000000003, 0.21680000000000002, 0.3583, 0.9541000000000001, 1.4113, 1.6911, 1.2494, 1.1895, 0.6909000000000001, 0.4736, 0.1754, 0.0582, 0.21730000000000002, 0.0785, 0.8249000000000001, 0.7638, 0.1095, 0.25680000000000003, 0.08950000000000001, 0.15760000000000002, 0.7727, 0.1573, 0.5043, 1.0444, 0.4766, 0.5588000000000001, 0.9054000000000001, 1.0125, 1.0482, 1.044, 0.45220000000000005, 0.211, 0.0461, 0.082, 0.06430000000000001, 0.1526, 0.08940000000000001, 0.5081, 1.0745, 0.3215, 0.0716, 0.0244, 0.0123, 0.19840000000000002, 0.49610000000000004, 1.0641, 0.6394000000000001, 0.6789000000000001, 0.365, 0.1741, 0.1408, 0.1646, 0.5389, 0.683, 0.4273, 0.052700000000000004, 0.0693, 0.1398, 0.2937, 0.23620000000000002, 0.5731]),\n",
       "       list([0.44820000000000004, 1.4822, 1.1819, 0.7434000000000001, 0.7148, 0.6529, 0.22390000000000002, 0.1927, 0.19690000000000002, 0.3033, 0.6176, 0.38580000000000003, 1.0418, 0.6581, 1.1053, 0.6224000000000001, 0.4591, 0.19890000000000002, 0.1632, 0.5538000000000001, 0.6342, 0.25470000000000004, 0.17420000000000002, 0.2447, 0.1331, 0.09580000000000001, 0.29760000000000003, 0.4863, 0.7058, 0.4929, 0.3874, 0.10490000000000001, 0.0915, 0.34900000000000003, 0.6972, 0.0789, 0.0442, 0.29, 0.25420000000000004, 0.8123, 0.7938000000000001, 0.26830000000000004, 0.6897, 0.4113, 0.9513, 0.1182, 0.056900000000000006, 0.3467, 0.3766, 0.4152, 0.8663000000000001, 0.5321, 0.5652, 0.0862, 0.09910000000000001, 0.44420000000000004, 0.08850000000000001, 0.0444, 0.14250000000000002, 0.355, 0.3352, 0.28040000000000004, 0.3229, 0.8048000000000001, 0.3103, 0.6449, 0.04, 0.5446]),\n",
       "       list([0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.1337, 0.22990000000000002, 0.051000000000000004, 0.0, 0.0442, 0.0, 0.0, 0.12810000000000002, 0.0539, 0.0352, 0.0917, 0.0796, 0.1317, 0.5695, 0.0665, 0.0252, 0.29810000000000003, 0.2654, 0.19460000000000002, 0.7547, 0.3346, 0.251, 0.5642, 0.5482, 0.3196, 0.6753, 0.4833, 0.4534, 0.2666, 0.459, 0.2078, 0.8759, 1.2778, 0.064, 0.40190000000000003, 0.3735, 0.1985, 0.6163000000000001, 0.2117, 0.068, 0.036000000000000004, 0.3497, 0.5744, 0.0941, 0.0405, 0.035500000000000004, 0.0089, 0.022600000000000002, 0.026500000000000003, 0.0529, 0.1621, 0.0023, 0.0505, 0.0371, 0.031, 0.0173, 0.0734, 0.14120000000000002, 0.6143000000000001, 0.2447, 0.1107, 0.22610000000000002, 0.32380000000000003]),\n",
       "       ...,\n",
       "       list([0.2891, 0.4496, 0.7165, 0.7128, 0.5931000000000001, 0.3504, 0.44870000000000004, 0.5889, 0.27990000000000004, 0.8551000000000001, 0.7762, 0.3123, 0.3597, 0.34040000000000004, 0.44820000000000004, 0.727, 0.0665, 0.6149, 0.096, 0.49360000000000004, 0.40540000000000004, 0.22940000000000002, 0.5747, 0.4419, 0.22890000000000002, 0.21250000000000002, 0.2798, 0.42110000000000003, 0.22840000000000002, 0.1265, 0.4012, 0.2831, 0.4413, 0.4106, 0.1998, 0.4758, 0.5135000000000001, 0.17450000000000002, 0.25220000000000004, 0.3064, 0.2401, 0.1154, 0.1976, 0.251, 0.3035, 0.41910000000000003, 0.2913, 0.1617, 0.49060000000000004, 0.49970000000000003, 0.2388, 0.3103, 0.38070000000000004, 0.5522, 0.2495, 0.23550000000000001, 0.47600000000000003, 0.182, 0.833, 0.37560000000000004, 0.4428, 0.9051, 0.669, 0.4697, 0.3113, 0.8738, 0.2816, 0.554]),\n",
       "       list([0.6919000000000001, 1.4823, 1.3685, 1.2473, 0.1953, 0.0329, 0.6012000000000001, 0.9031, 0.5073, 0.6996, 0.3976, 0.34450000000000003, 0.3476, 1.0195, 0.5443, 0.18610000000000002, 0.49520000000000003, 0.022600000000000002, 0.4293, -0.36150000000000004, -0.010100000000000001, -0.0545, -0.17420000000000002, 0.3027, 0.2243, 0.3493, 0.17650000000000002, 0.07010000000000001, 0.0876, -0.0222, 0.1981, 0.1824, 0.16590000000000002, 0.1593, 0.13, 0.15430000000000002, 0.11510000000000001, 0.0252, 0.0791, 0.0555, 0.0159, 0.1287, 0.0718, 0.13190000000000002, 0.1121, 0.1177, 0.32980000000000004, 0.1791, 0.4717, 0.30910000000000004, 0.22790000000000002, 0.33890000000000003, 0.766, 0.6367, 0.5952000000000001, 0.2506, 0.3242, 0.9117000000000001, 0.5795, 0.6046, 0.7225, 0.5599000000000001, 0.849, 0.2333, 0.2155, 0.9315, 0.2745, 0.1013]),\n",
       "       list([1.0102, 1.7928000000000002, 1.9228, 0.9649000000000001, 0.5666, 0.2154, 0.0455, 0.012700000000000001, 0.02, 0.025400000000000002, 0.27690000000000003, 0.2242, 1.0684, 0.49770000000000003, 0.2255, 0.0621, 0.0507, 0.095, 0.056, 0.0444, 0.1978, 2.0917, 1.2969, 0.553, 0.1053, 0.1784, 0.0441, 0.46840000000000004, 1.4506000000000001, 0.2059, 0.1908, 0.48260000000000003, 0.1558, 0.4904, 0.024300000000000002, 0.0074, 0.0, 0.023100000000000002, 0.024200000000000003, 0.0, -0.0105, 0.0177, 0.0877, 0.26890000000000003, 1.4352, 1.9672, 0.2942, 0.12480000000000001, 0.0779, 0.029400000000000003, 0.024800000000000003, 0.0429, 0.0357, 0.192, 1.1468, 0.0057, 0.022, 0.06520000000000001, 0.43320000000000003, 0.4378, 0.23020000000000002, 0.4202, 0.6952, 0.027200000000000002, 0.038200000000000005, 0.0381, -0.0066, 0.07060000000000001])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1887, 68, 3), dtype=float64, numpy=\n",
       "array([[[0.3041, 0.3322, 0.4213],\n",
       "        [1.7311, 1.6811, 1.3996],\n",
       "        [1.2554, 0.8533, 1.1203],\n",
       "        ...,\n",
       "        [0.2271, 0.2281, 0.2264],\n",
       "        [0.2261, 0.3028, 0.2245],\n",
       "        [0.5701, 0.8259, 0.2462]],\n",
       "\n",
       "       [[0.8709, 0.4808, 0.4952],\n",
       "        [3.4296, 3.2291, 3.6226],\n",
       "        [1.564 , 2.2518, 2.0154],\n",
       "        ...,\n",
       "        [0.5661, 0.5359, 0.9449],\n",
       "        [0.9591, 0.3728, 0.4612],\n",
       "        [0.182 , 1.0262, 0.8275]],\n",
       "\n",
       "       [[0.7129, 0.8175, 0.3888],\n",
       "        [1.9962, 4.2932, 3.0685],\n",
       "        [0.733 , 1.0769, 1.0348],\n",
       "        ...,\n",
       "        [0.03  , 0.2056, 0.081 ],\n",
       "        [0.0518, 0.7357, 0.481 ],\n",
       "        [0.7724, 0.8423, 0.2484]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.1755, 0.7854, 0.7026],\n",
       "        [1.6162, 5.2026, 2.6689],\n",
       "        [1.385 , 1.1572, 1.051 ],\n",
       "        ...,\n",
       "        [0.0478, 0.3731, 0.101 ],\n",
       "        [0.1235, 0.9291, 0.5529],\n",
       "        [0.4677, 0.8325, 0.6064]],\n",
       "\n",
       "       [[0.1603, 0.1387, 0.25  ],\n",
       "        [0.4112, 0.7426, 0.7678],\n",
       "        [0.5019, 0.4104, 0.5029],\n",
       "        ...,\n",
       "        [0.0306, 0.1505, 0.066 ],\n",
       "        [0.0118, 0.1191, 0.0946],\n",
       "        [0.0183, 0.1795, 0.1864]],\n",
       "\n",
       "       [[0.7579, 0.7713, 0.4801],\n",
       "        [2.266 , 3.0089, 3.0273],\n",
       "        [1.742 , 0.3797, 0.5943],\n",
       "        ...,\n",
       "        [0.8495, 0.7897, 0.9632],\n",
       "        [0.5989, 0.6496, 0.6959],\n",
       "        [0.3433, 0.5518, 0.3826]]])>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
