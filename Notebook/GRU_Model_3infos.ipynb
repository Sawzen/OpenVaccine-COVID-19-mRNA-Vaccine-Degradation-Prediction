{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import plotly.express as px\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu de données initial \n",
    "train = pd.read_json(\"train.json\", lines = True)\n",
    "test = pd.read_json(\"test.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"signal_to_noise >= 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_set(df, list_column):\n",
    "    \"\"\"\n",
    "    Fonction qui crée d'une fenetre de lecture de 68 bases. \n",
    "        :Parameters:\n",
    "            df = un data frame train\n",
    "            list_column = numero de la colonne du data frame \n",
    "        :Return:\n",
    "            deux data frame :\n",
    "                first68_train = data frame contenant les 68 premieres bases et annotations de structure\n",
    "                last68_train = data frame contenant les 68 dernieres bases et annotations de structure\n",
    "    \"\"\"\n",
    "    first68 = df.copy()\n",
    "    last68 = df.copy()\n",
    "    for a in list_column :\n",
    "        for i, r in enumerate(df.iloc[:,a]):\n",
    "            first68.iloc[i,a] = r[0:68]\n",
    "            last68.iloc[i,a] = r[len(r)-68:]\n",
    "    return first68, last68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first68_train, last68_train = divide_set(train, [2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>...</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>One_hot seq</th>\n",
       "      <th>One hot strucure</th>\n",
       "      <th>encoding predicted loop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>id_00ab2d761</td>\n",
       "      <td>GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...</td>\n",
       "      <td>.....(.(((((.(((((((((...........)))))))..(((....</td>\n",
       "      <td>EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...</td>\n",
       "      <td>4.136</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.165, 0.20520000000000002, 0.179, 0.1333, 0....</td>\n",
       "      <td>[0.2864, 0.24710000000000001, 0.2222, 0.1903, ...</td>\n",
       "      <td>[0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...</td>\n",
       "      <td>[0.9559000000000001, 1.9442, 1.0114, 0.5105000...</td>\n",
       "      <td>[1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...</td>\n",
       "      <td>[0.22460000000000002, 1.7281, 1.381, 0.6623, 0...</td>\n",
       "      <td>[0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>id_00abef1d7</td>\n",
       "      <td>GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...</td>\n",
       "      <td>.........((((((((......((((((((((((....)))))))...</td>\n",
       "      <td>EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>2.485</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.422, 0.5478000000000001, 0.4749000000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...</td>\n",
       "      <td>[0.9306000000000001, 1.0496, 0.5844, 0.7796000...</td>\n",
       "      <td>[0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...</td>\n",
       "      <td>[0.46040000000000003, 3.6695, 0.78550000000000...</td>\n",
       "      <td>[2.7711, 7.365, 1.6924000000000001, 1.43840000...</td>\n",
       "      <td>[1.073, 2.8604000000000003, 1.9936, 1.0273, 1....</td>\n",
       "      <td>[2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>id_00b436dec</td>\n",
       "      <td>GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...</td>\n",
       "      <td>.....(((((((((((..(((((((((..((((....))))..)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...</td>\n",
       "      <td>1.727</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.4843, 0.5233, 0.4554, 0.43520000000000003, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.384, 0.723, 0.4766, 0.30260000000000004, 0....</td>\n",
       "      <td>[0.7429, 0.9137000000000001, 0.480400000000000...</td>\n",
       "      <td>[1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...</td>\n",
       "      <td>[1.6912, 5.2652, 2.3901, 0.45890000000000003, ...</td>\n",
       "      <td>[1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...</td>\n",
       "      <td>[0.49060000000000004, 4.6339, 1.95860000000000...</td>\n",
       "      <td>[1.2852000000000001, 2.5460000000000003, 0.234...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2394</td>\n",
       "      <td>id_ff13729b0</td>\n",
       "      <td>GGAAAUAAAUAAAUAACAAUAAAGAGAUAAGACACAAUAAAUAAAA...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...</td>\n",
       "      <td>1.995</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.3019, 0.33680000000000004, 0.25980000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25930000000000003, 0.3074, 0.2109, 0.1995, ...</td>\n",
       "      <td>[0.465, 0.6078, 0.30310000000000004, 0.3873000...</td>\n",
       "      <td>[0.3517, 0.5358, 0.4318, 0.016900000000000002,...</td>\n",
       "      <td>[0.6612, 1.0221, 0.1676, 0.1648, 0.5634, 0.645...</td>\n",
       "      <td>[4.0973, 2.0778, 0.2776, 0.1207, 0.63140000000...</td>\n",
       "      <td>[0.2661, 0.5771000000000001, 0.3517, 0.295, 0....</td>\n",
       "      <td>[0.2897, 1.1666, 0.135, 0.4742, 0.9522, 0.8408...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2395</td>\n",
       "      <td>id_ff84602f7</td>\n",
       "      <td>GGAAAAUAGCAGAGGAAAUACUAGAGCAAUUGCAAAGGCCGAUCAU...</td>\n",
       "      <td>........((..((......))...)).........(((..........</td>\n",
       "      <td>EEEEEEEESSIISSHHHHHHSSIIISSXXXXXXXXXSSSHHHHHHH...</td>\n",
       "      <td>4.036</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2585, 0.29710000000000003, 0.2748, 0.205000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2093, 0.2985, 0.2922, 0.08360000000000001, ...</td>\n",
       "      <td>[0.29460000000000003, 0.40850000000000003, 0.3...</td>\n",
       "      <td>[0.6957, 1.251, 1.3235999999999999, 0.7521, 0....</td>\n",
       "      <td>[0.6439, 2.0117, 1.3682, 0.0918, 0.65860000000...</td>\n",
       "      <td>[2.1589, 3.3601, 1.6179000000000001, 0.1344000...</td>\n",
       "      <td>[0.47900000000000004, 1.9583, 2.4635, 0.0512, ...</td>\n",
       "      <td>[0.5759000000000001, 2.3736, 1.4158, 0.1914000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2396</td>\n",
       "      <td>id_ff85fcdba</td>\n",
       "      <td>GGAAAACAAAAACAAACAACAAAAACAAACAACAAAAACAAACAAC...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...</td>\n",
       "      <td>3.227</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2169, 0.2513, 0.2303, 0.22260000000000002, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2758, 0.3659, 0.2155, 0.28340000000000004, ...</td>\n",
       "      <td>[0.401, 0.388, 0.3403, 0.3608, 0.3057, 0.242, ...</td>\n",
       "      <td>[0.2891, 0.4496, 0.7165, 0.7128, 0.59310000000...</td>\n",
       "      <td>[0.3619, 0.6924, 0.2988, 0.3639, 0.545, 0.2263...</td>\n",
       "      <td>[2.8541, 1.6106, 1.4343, 1.0797, 0.6803, 0.559...</td>\n",
       "      <td>[0.2964, 0.9351, 0.2555, 0.7603000000000001, 0...</td>\n",
       "      <td>[0.6526000000000001, 0.2548, 0.6927, 0.9316000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>id_ffe06f3fe</td>\n",
       "      <td>GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...</td>\n",
       "      <td>.....((((..(....)..))))......(((....)))..........</td>\n",
       "      <td>EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...</td>\n",
       "      <td>5.553</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1431, 0.1847, 0.15960000000000002, 0.1466, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0944, 0.1453, 0.1067, 0.0994, 0.06470000000...</td>\n",
       "      <td>[0.1691, 0.22740000000000002, 0.178, 0.1762, 0...</td>\n",
       "      <td>[0.6919000000000001, 1.4823, 1.3685, 1.2473, 0...</td>\n",
       "      <td>[0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...</td>\n",
       "      <td>[2.7157999999999998, 3.1249000000000002, 1.137...</td>\n",
       "      <td>[0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...</td>\n",
       "      <td>[0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>id_fff546103</td>\n",
       "      <td>GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...</td>\n",
       "      <td>.....((((((((((((((((...)))).)))).((((((((((.....</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...</td>\n",
       "      <td>6.545</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1782, 0.2043, 0.1842, 0.13240000000000002, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.22060000000000002, 0.254, 0.2109, 0.1636, 0...</td>\n",
       "      <td>[0.2379, 0.27590000000000003, 0.22160000000000...</td>\n",
       "      <td>[1.0102, 1.7928000000000002, 1.9228, 0.9649000...</td>\n",
       "      <td>[1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...</td>\n",
       "      <td>[2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...</td>\n",
       "      <td>[1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...</td>\n",
       "      <td>[0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2097 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index            id                                           sequence  \\\n",
       "0         0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "2         2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "5         5  id_00ab2d761  GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...   \n",
       "6         6  id_00abef1d7  GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...   \n",
       "7         7  id_00b436dec  GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...   \n",
       "...     ...           ...                                                ...   \n",
       "2394   2394  id_ff13729b0  GGAAAUAAAUAAAUAACAAUAAAGAGAUAAGACACAAUAAAUAAAA...   \n",
       "2395   2395  id_ff84602f7  GGAAAAUAGCAGAGGAAAUACUAGAGCAAUUGCAAAGGCCGAUCAU...   \n",
       "2396   2396  id_ff85fcdba  GGAAAACAAAAACAAACAACAAAAACAAACAACAAAAACAAACAAC...   \n",
       "2398   2398  id_ffe06f3fe  GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...   \n",
       "2399   2399  id_fff546103  GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...   \n",
       "\n",
       "                                              structure  \\\n",
       "0     .....((((((.......)))).)).((.....((..((((((......   \n",
       "2     .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "5     .....(.(((((.(((((((((...........)))))))..(((....   \n",
       "6     .........((((((((......((((((((((((....)))))))...   \n",
       "7     .....(((((((((((..(((((((((..((((....))))..)))...   \n",
       "...                                                 ...   \n",
       "2394  .................................................   \n",
       "2395  ........((..((......))...)).........(((..........   \n",
       "2396  .................................................   \n",
       "2398  .....((((..(....)..))))......(((....)))..........   \n",
       "2399  .....((((((((((((((((...)))).)))).((((((((((.....   \n",
       "\n",
       "                                    predicted_loop_type  signal_to_noise  \\\n",
       "0     EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "2     EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "5     EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...            4.136   \n",
       "6     EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...            2.485   \n",
       "7     EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...            1.727   \n",
       "...                                                 ...              ...   \n",
       "2394  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...            1.995   \n",
       "2395  EEEEEEEESSIISSHHHHHHSSIIISSXXXXXXXXXSSSHHHHHHH...            4.036   \n",
       "2396  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...            3.227   \n",
       "2398  EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...            5.553   \n",
       "2399  EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...            6.545   \n",
       "\n",
       "      SN_filter  seq_length  seq_scored  \\\n",
       "0             1         107          68   \n",
       "2             1         107          68   \n",
       "5             1         107          68   \n",
       "6             1         107          68   \n",
       "7             1         107          68   \n",
       "...         ...         ...         ...   \n",
       "2394          0         107          68   \n",
       "2395          1         107          68   \n",
       "2396          1         107          68   \n",
       "2398          0         107          68   \n",
       "2399          1         107          68   \n",
       "\n",
       "                                       reactivity_error  ...  \\\n",
       "0     [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  ...   \n",
       "2     [0.0931, 0.13290000000000002, 0.11280000000000...  ...   \n",
       "5     [0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...  ...   \n",
       "6     [0.422, 0.5478000000000001, 0.4749000000000000...  ...   \n",
       "7     [0.4843, 0.5233, 0.4554, 0.43520000000000003, ...  ...   \n",
       "...                                                 ...  ...   \n",
       "2394  [0.3019, 0.33680000000000004, 0.25980000000000...  ...   \n",
       "2395  [0.2585, 0.29710000000000003, 0.2748, 0.205000...  ...   \n",
       "2396  [0.2169, 0.2513, 0.2303, 0.22260000000000002, ...  ...   \n",
       "2398  [0.1431, 0.1847, 0.15960000000000002, 0.1466, ...  ...   \n",
       "2399  [0.1782, 0.2043, 0.1842, 0.13240000000000002, ...  ...   \n",
       "\n",
       "                                       deg_error_Mg_50C  \\\n",
       "0     [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "2     [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "5     [0.165, 0.20520000000000002, 0.179, 0.1333, 0....   \n",
       "6     [0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...   \n",
       "7     [0.384, 0.723, 0.4766, 0.30260000000000004, 0....   \n",
       "...                                                 ...   \n",
       "2394  [0.25930000000000003, 0.3074, 0.2109, 0.1995, ...   \n",
       "2395  [0.2093, 0.2985, 0.2922, 0.08360000000000001, ...   \n",
       "2396  [0.2758, 0.3659, 0.2155, 0.28340000000000004, ...   \n",
       "2398  [0.0944, 0.1453, 0.1067, 0.0994, 0.06470000000...   \n",
       "2399  [0.22060000000000002, 0.254, 0.2109, 0.1636, 0...   \n",
       "\n",
       "                                          deg_error_50C  \\\n",
       "0     [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "2     [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "5     [0.2864, 0.24710000000000001, 0.2222, 0.1903, ...   \n",
       "6     [0.9306000000000001, 1.0496, 0.5844, 0.7796000...   \n",
       "7     [0.7429, 0.9137000000000001, 0.480400000000000...   \n",
       "...                                                 ...   \n",
       "2394  [0.465, 0.6078, 0.30310000000000004, 0.3873000...   \n",
       "2395  [0.29460000000000003, 0.40850000000000003, 0.3...   \n",
       "2396  [0.401, 0.388, 0.3403, 0.3608, 0.3057, 0.242, ...   \n",
       "2398  [0.1691, 0.22740000000000002, 0.178, 0.1762, 0...   \n",
       "2399  [0.2379, 0.27590000000000003, 0.22160000000000...   \n",
       "\n",
       "                                             reactivity  \\\n",
       "0     [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "2     [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "5     [0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...   \n",
       "6     [0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...   \n",
       "7     [1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...   \n",
       "...                                                 ...   \n",
       "2394  [0.3517, 0.5358, 0.4318, 0.016900000000000002,...   \n",
       "2395  [0.6957, 1.251, 1.3235999999999999, 0.7521, 0....   \n",
       "2396  [0.2891, 0.4496, 0.7165, 0.7128, 0.59310000000...   \n",
       "2398  [0.6919000000000001, 1.4823, 1.3685, 1.2473, 0...   \n",
       "2399  [1.0102, 1.7928000000000002, 1.9228, 0.9649000...   \n",
       "\n",
       "                                            deg_Mg_pH10  \\\n",
       "0     [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "2     [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "5     [0.9559000000000001, 1.9442, 1.0114, 0.5105000...   \n",
       "6     [0.46040000000000003, 3.6695, 0.78550000000000...   \n",
       "7     [1.6912, 5.2652, 2.3901, 0.45890000000000003, ...   \n",
       "...                                                 ...   \n",
       "2394  [0.6612, 1.0221, 0.1676, 0.1648, 0.5634, 0.645...   \n",
       "2395  [0.6439, 2.0117, 1.3682, 0.0918, 0.65860000000...   \n",
       "2396  [0.3619, 0.6924, 0.2988, 0.3639, 0.545, 0.2263...   \n",
       "2398  [0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...   \n",
       "2399  [1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...   \n",
       "\n",
       "                                               deg_pH10  \\\n",
       "0     [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "2     [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "5     [1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...   \n",
       "6     [2.7711, 7.365, 1.6924000000000001, 1.43840000...   \n",
       "7     [1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...   \n",
       "...                                                 ...   \n",
       "2394  [4.0973, 2.0778, 0.2776, 0.1207, 0.63140000000...   \n",
       "2395  [2.1589, 3.3601, 1.6179000000000001, 0.1344000...   \n",
       "2396  [2.8541, 1.6106, 1.4343, 1.0797, 0.6803, 0.559...   \n",
       "2398  [2.7157999999999998, 3.1249000000000002, 1.137...   \n",
       "2399  [2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...   \n",
       "\n",
       "                                             deg_Mg_50C  \\\n",
       "0     [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "2     [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "5     [0.22460000000000002, 1.7281, 1.381, 0.6623, 0...   \n",
       "6     [1.073, 2.8604000000000003, 1.9936, 1.0273, 1....   \n",
       "7     [0.49060000000000004, 4.6339, 1.95860000000000...   \n",
       "...                                                 ...   \n",
       "2394  [0.2661, 0.5771000000000001, 0.3517, 0.295, 0....   \n",
       "2395  [0.47900000000000004, 1.9583, 2.4635, 0.0512, ...   \n",
       "2396  [0.2964, 0.9351, 0.2555, 0.7603000000000001, 0...   \n",
       "2398  [0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...   \n",
       "2399  [1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...   \n",
       "\n",
       "                                                deg_50C  \\\n",
       "0     [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...   \n",
       "2     [0.9501000000000001, 1.7974999999999999, 1.499...   \n",
       "5     [0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...   \n",
       "6     [2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...   \n",
       "7     [1.2852000000000001, 2.5460000000000003, 0.234...   \n",
       "...                                                 ...   \n",
       "2394  [0.2897, 1.1666, 0.135, 0.4742, 0.9522, 0.8408...   \n",
       "2395  [0.5759000000000001, 2.3736, 1.4158, 0.1914000...   \n",
       "2396  [0.6526000000000001, 0.2548, 0.6927, 0.9316000...   \n",
       "2398  [0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...   \n",
       "2399  [0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...   \n",
       "\n",
       "                                            One_hot seq  \\\n",
       "0     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "5     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "6     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "7     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "...                                                 ...   \n",
       "2394  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2395  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2396  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2398  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2399  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "\n",
       "                                       One hot strucure  \\\n",
       "0     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "5     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "6     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "7     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "...                                                 ...   \n",
       "2394  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2395  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2396  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2398  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2399  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "\n",
       "                                encoding predicted loop  \n",
       "0     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "5     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "6     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "7     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2394  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2395  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2396  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2398  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2399  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2097 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encoding(df, name_colonne):\n",
    "    \"\"\"\n",
    "    Fonction pour encoder les sequences, structures et type boucles : One hot encoding\n",
    "        :Parameters:\n",
    "            df = data frame : train et test de départ\n",
    "            name_colonne = le nom de la colonne du df \n",
    "        :Return:\n",
    "            un tableau\n",
    "    \"\"\"\n",
    "    frst_lst = []\n",
    "    for r in df[name_colonne]:\n",
    "        for i in range(len(r)):\n",
    "            if r[i] not in frst_lst:\n",
    "                frst_lst.append(r[i])\n",
    "    dico = {}\n",
    "    ar = np.zeros(shape=(1,len(frst_lst)),dtype=int)\n",
    "    for i, l in enumerate(frst_lst):\n",
    "        ar2 = ar.copy()\n",
    "        ar2[0][i]=1\n",
    "        dico[l]=ar2\n",
    "    scnd_lst = []\n",
    "    for r in df[name_colonne]:\n",
    "        lst = [] \n",
    "        for i in range(len(r)):\n",
    "            #print(dico[r[i]], r[i])\n",
    "            lst.append(dico[r[i]])\n",
    "        scnd_lst.append(lst)\n",
    "    return np.array(scnd_lst)\n",
    "\n",
    "tab = one_hot_encoding(first68_train, 'sequence')\n",
    "tab2 = one_hot_encoding(first68_train, 'structure')\n",
    "tab3 = one_hot_encoding(first68_train, 'predicted_loop_type')\n",
    "\n",
    "first68_train[\"One_hot seq\"] = tab.tolist() # ajout des colonnes encoding a notre DF de départ\n",
    "first68_train[\"One hot strucure\"] = tab2.tolist()\n",
    "first68_train[\"encoding predicted loop\"] = tab3.tolist()\n",
    "first68_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_format(df, colname):\n",
    "    \"\"\"\n",
    "    juste pck j'crois que y'avait des liste dans des listes\n",
    "    j'ai transformé en liste d'array\n",
    "    \"\"\"\n",
    "    x1 = df[colname].copy()\n",
    "    x2 = []\n",
    "    for r in x1:\n",
    "        lst = []\n",
    "        for u in r:\n",
    "            lst.append(np.array(u[0], float))\n",
    "        lst = np.array(lst)\n",
    "        x2.append(lst)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097, 68, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = right_format(first68_train, \"One_hot seq\")\n",
    "x_strct = right_format(first68_train, \"One hot strucure\")\n",
    "x_loop = right_format(first68_train, \"encoding predicted loop\")\n",
    "\n",
    "#print(len(x_seq))\n",
    "#print(len(x_strct))\n",
    "#print(len(x_loop))\n",
    "x_seq = np.array(x_seq)\n",
    "x_strct = np.array(x_strct)\n",
    "x_loop = np.array(x_loop)\n",
    "x_all = np.concatenate((x_seq, x_strct,x_loop), axis=2)\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.random.normal((32, 68, 5))\n",
    "y_pred = tf.random.normal((32, 68, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    re = tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    print(re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.GRU(\n",
    "        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))\n",
    "\n",
    "def build_model(embed_size, seq_len=68, pred_len=68, dropout=0.5, \n",
    "                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=3):\n",
    "    inputs = L.Input(shape=(seq_len, 14))# 107 longueur sequence - 4 ATGU\n",
    "    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n",
    "\n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, 68,  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n",
    "    \n",
    "    for x in range(n_layers):\n",
    "        print(x,\"layer\")\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    # Since we are only making predictions on the first part of each sequence, \n",
    "    # we have to truncate it\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    out = L.Dense(5, activation='relu')(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(), loss=MCRMSE, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pandas_list_to_array(train[pred_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1887, 68, 14)\n",
      "(1887, 68, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_all, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 layer\n",
      "1 layer\n",
      "2 layer\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 68, 14)]          0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 68, 14, 200)       2800      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(None, 68, 2800)]        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 68, 2800)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 68, 512)           4697088   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 68, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 68, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 68, 512)]         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 68, 5)             2565      \n",
      "=================================================================\n",
      "Total params: 7,067,893\n",
      "Trainable params: 7,067,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(embed_size=14)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.2460Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n",
      "30/30 [==============================] - 218s 7s/step - loss: 0.5505 - accuracy: 0.2460 - val_loss: 0.4156 - val_accuracy: 0.2229\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n",
    "        tf.keras.callbacks.ModelCheckpoint('model.h5')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu, rmsprop, 3 couches, noeaud(256 128 85), 30 epochs : \n",
    "# loss: 0.2735 - accuracy: 0.4391 - val_loss: 0.2643 - val_accuracy: 0.4440\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 128 85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5505052804946899],\n",
       " 'accuracy': [0.2459864765405655],\n",
       " 'val_loss': [0.41559648513793945],\n",
       " 'val_accuracy': [0.2228991538286209],\n",
       " 'lr': [0.001]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(256, int(256/2), int(256/3))\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(\n",
    "    history.history, y=['loss', 'accuracy', 'val_loss', 'val_accuracy'],\n",
    "    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n",
    "    title='Training History')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097, 68, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last68_train\n",
    "t = one_hot_encoding(last68_train, 'sequence')\n",
    "t2 = one_hot_encoding(last68_train, 'structure')\n",
    "t3 = one_hot_encoding(last68_train, 'predicted_loop_type')\n",
    "\n",
    "last68_train[\"One_hot seq\"] = t.tolist() # ajout des colonnes encoding a notre DF de départ\n",
    "last68_train[\"One hot strucure\"] = t2.tolist()\n",
    "last68_train[\"encoding predicted loop\"] = t3.tolist()\n",
    "last68_train\n",
    "\n",
    "x_seq2 = right_format(last68_train, \"One_hot seq\")\n",
    "x_strct2 = right_format(last68_train, \"One hot strucure\")\n",
    "x_loop2 = right_format(last68_train, \"encoding predicted loop\")\n",
    "\n",
    "#print(len(x_seq))\n",
    "#print(len(x_strct))\n",
    "#print(len(x_loop))\n",
    "x_seq2 = np.array(x_seq2)\n",
    "x_strct2 = np.array(x_strct2)\n",
    "x_loop2 = np.array(x_loop2)\n",
    "x_all2 = np.concatenate((x_seq2, x_strct2,x_loop2), axis=2)\n",
    "x_all2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "train1_preds = model.predict(x_all)\n",
    "train2_preds = model.predict(x_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.90393806, 0.6613666 , 0.91118795, 1.5056193 , 0.9298657 ],\n",
       "        [1.1889478 , 0.88627654, 1.1505041 , 1.6896155 , 1.118321  ],\n",
       "        [1.2566925 , 0.93215555, 1.2239708 , 1.5971904 , 1.1345354 ],\n",
       "        ...,\n",
       "        [0.44921324, 0.38045922, 0.5262022 , 0.48042727, 0.4627806 ],\n",
       "        [0.37794954, 0.32218608, 0.43487206, 0.3431243 , 0.37883466],\n",
       "        [0.26133105, 0.2288419 , 0.28810087, 0.14659883, 0.25699896]],\n",
       "\n",
       "       [[0.88801134, 0.6497552 , 0.8943719 , 1.4834915 , 0.9170171 ],\n",
       "        [1.1606777 , 0.8673179 , 1.1258777 , 1.656759  , 1.0978813 ],\n",
       "        [1.2116538 , 0.90511316, 1.191824  , 1.5528655 , 1.104795  ],\n",
       "        ...,\n",
       "        [0.2600085 , 0.4192485 , 0.3797747 , 0.24643084, 0.27848563],\n",
       "        [0.26271713, 0.38610294, 0.31940877, 0.1900029 , 0.24798624],\n",
       "        [0.23871613, 0.30569872, 0.24546069, 0.09623206, 0.19423725]],\n",
       "\n",
       "       [[0.8852091 , 0.6435987 , 0.8899377 , 1.4749409 , 0.9131397 ],\n",
       "        [1.1582663 , 0.8589161 , 1.1218555 , 1.6475452 , 1.0935574 ],\n",
       "        [1.212607  , 0.8957257 , 1.190337  , 1.5451556 , 1.1016676 ],\n",
       "        ...,\n",
       "        [0.5586968 , 0.4395317 , 0.63690656, 0.557466  , 0.5297367 ],\n",
       "        [0.38815293, 0.31236464, 0.47252294, 0.3289034 , 0.38315424],\n",
       "        [0.24824041, 0.2060681 , 0.2961328 , 0.12074461, 0.24955234]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.7538946 , 0.4831629 , 0.7997503 , 1.3498615 , 0.83481014],\n",
       "        [1.0021702 , 0.65086585, 1.0413666 , 1.5230359 , 1.0164015 ],\n",
       "        [1.0697771 , 0.66376615, 1.1577791 , 1.4665645 , 1.056816  ],\n",
       "        ...,\n",
       "        [0.6693399 , 0.31977835, 0.7371828 , 0.64504987, 0.6982646 ],\n",
       "        [0.53803384, 0.25788602, 0.5602743 , 0.4101101 , 0.55153644],\n",
       "        [0.21731809, 0.08665404, 0.27607748, 0.        , 0.26678836]],\n",
       "\n",
       "       [[0.88336104, 0.63886446, 0.8825528 , 1.4725066 , 0.91039133],\n",
       "        [1.1482129 , 0.8459881 , 1.1056836 , 1.6349708 , 1.0854114 ],\n",
       "        [1.1837912 , 0.8668838 , 1.1602514 , 1.5124676 , 1.0817401 ],\n",
       "        ...,\n",
       "        [0.52181584, 0.3640817 , 0.61164373, 0.4977961 , 0.53075814],\n",
       "        [0.36300662, 0.2682486 , 0.43649757, 0.26976177, 0.37718847],\n",
       "        [0.07519164, 0.07804178, 0.19563726, 0.        , 0.13456158]],\n",
       "\n",
       "       [[0.90395206, 0.66820556, 0.9123871 , 1.5048337 , 0.930567  ],\n",
       "        [1.1829023 , 0.8938257 , 1.1499298 , 1.6849779 , 1.1156929 ],\n",
       "        [1.2397264 , 0.93991625, 1.2220607 , 1.5877951 , 1.1264341 ],\n",
       "        ...,\n",
       "        [0.03790671, 0.277483  , 0.16842768, 0.00492962, 0.10006367],\n",
       "        [0.        , 0.17118733, 0.06567173, 0.        , 0.        ],\n",
       "        [0.        , 0.07315848, 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9082878 , 0.66908693, 0.84680086, 1.424108  , 0.8908664 ],\n",
       "        [1.059046  , 0.8083022 , 0.9850202 , 1.4411715 , 0.97634697],\n",
       "        [0.88460743, 0.72183865, 0.90921855, 1.158859  , 0.8347094 ],\n",
       "        ...,\n",
       "        [0.02104485, 0.19813141, 0.09922462, 0.        , 0.06778613],\n",
       "        [0.00353262, 0.151982  , 0.04713656, 0.        , 0.03283549],\n",
       "        [0.03855949, 0.13369955, 0.02045606, 0.        , 0.02326482]],\n",
       "\n",
       "       [[0.21420045, 0.32312328, 0.24818683, 0.5171417 , 0.28661913],\n",
       "        [0.24111669, 0.3939018 , 0.24212185, 0.44039842, 0.2927215 ],\n",
       "        [0.09266131, 0.32597846, 0.17589271, 0.21445985, 0.16954954],\n",
       "        ...,\n",
       "        [0.0210466 , 0.19813363, 0.09922563, 0.        , 0.06778987],\n",
       "        [0.00353378, 0.15198357, 0.04713756, 0.        , 0.03283784],\n",
       "        [0.03856023, 0.13370064, 0.02045688, 0.        , 0.02326625]],\n",
       "\n",
       "       [[0.3297636 , 0.33917516, 0.4332485 , 0.76115537, 0.44171545],\n",
       "        [0.36201075, 0.40864494, 0.50933146, 0.7450724 , 0.4675408 ],\n",
       "        [0.54859006, 0.54520434, 0.642674  , 0.8813595 , 0.5939711 ],\n",
       "        ...,\n",
       "        [0.02103324, 0.19811809, 0.09919154, 0.        , 0.06778996],\n",
       "        [0.00352644, 0.15197553, 0.04711754, 0.        , 0.03283969],\n",
       "        [0.03855638, 0.13369693, 0.02044549, 0.        , 0.02326896]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.14700821, 0.24902457, 0.23362572, 0.4554609 , 0.25034788],\n",
       "        [0.15225929, 0.3011854 , 0.23976685, 0.4121893 , 0.25524333],\n",
       "        [0.16156602, 0.33541003, 0.25406438, 0.37267604, 0.25462374],\n",
       "        ...,\n",
       "        [0.02104275, 0.19813031, 0.09921828, 0.        , 0.06778553],\n",
       "        [0.00353152, 0.15198176, 0.04713284, 0.        , 0.03283543],\n",
       "        [0.03855894, 0.13369972, 0.0204539 , 0.        , 0.02326504]],\n",
       "\n",
       "       [[0.26530093, 0.33615944, 0.32774115, 0.5870298 , 0.33205104],\n",
       "        [0.33266973, 0.43621626, 0.37015843, 0.588461  , 0.3742052 ],\n",
       "        [0.39615384, 0.5095057 , 0.4155697 , 0.5699432 , 0.4014604 ],\n",
       "        ...,\n",
       "        [0.02102858, 0.19810794, 0.09919114, 0.        , 0.06779075],\n",
       "        [0.00352314, 0.15196781, 0.04711678, 0.        , 0.03284024],\n",
       "        [0.03855418, 0.1336913 , 0.02044505, 0.        , 0.02326931]],\n",
       "\n",
       "       [[0.6761371 , 0.49515522, 0.70252836, 1.1928228 , 0.731175  ],\n",
       "        [0.9351168 , 0.7065583 , 0.89781016, 1.3929203 , 0.9153533 ],\n",
       "        [0.9467636 , 0.73234016, 0.9313695 , 1.2926449 , 0.9043577 ],\n",
       "        ...,\n",
       "        [0.02103298, 0.198117  , 0.09919558, 0.        , 0.06778879],\n",
       "        [0.00352598, 0.15197417, 0.04711961, 0.        , 0.03283872],\n",
       "        [0.03855594, 0.13369562, 0.02044658, 0.        , 0.02326816]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
