{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import plotly.express as px\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu de données initial \n",
    "train = pd.read_json(\"train.json\", lines = True)\n",
    "test = pd.read_json(\"test.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"signal_to_noise >= 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_set(df, list_column):\n",
    "    \"\"\"\n",
    "    Fonction qui crée d'une fenetre de lecture de 68 bases. \n",
    "        :Parameters:\n",
    "            df = un data frame train\n",
    "            list_column = numero de la colonne du data frame \n",
    "        :Return:\n",
    "            deux data frame :\n",
    "                first68_train = data frame contenant les 68 premieres bases et annotations de structure\n",
    "                last68_train = data frame contenant les 68 dernieres bases et annotations de structure\n",
    "    \"\"\"\n",
    "    first68 = df.copy()\n",
    "    last68 = df.copy()\n",
    "    for a in list_column :\n",
    "        for i, r in enumerate(df.iloc[:,a]):\n",
    "            first68.iloc[i,a] = r[0:68]\n",
    "            last68.iloc[i,a] = r[len(r)-68:]\n",
    "    return first68, last68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first68_train, last68_train = divide_set(train, [2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>...</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>One_hot seq</th>\n",
       "      <th>One hot strucure</th>\n",
       "      <th>encoding predicted loop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>id_00ab2d761</td>\n",
       "      <td>GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...</td>\n",
       "      <td>.....(.(((((.(((((((((...........)))))))..(((....</td>\n",
       "      <td>EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...</td>\n",
       "      <td>4.136</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.165, 0.20520000000000002, 0.179, 0.1333, 0....</td>\n",
       "      <td>[0.2864, 0.24710000000000001, 0.2222, 0.1903, ...</td>\n",
       "      <td>[0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...</td>\n",
       "      <td>[0.9559000000000001, 1.9442, 1.0114, 0.5105000...</td>\n",
       "      <td>[1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...</td>\n",
       "      <td>[0.22460000000000002, 1.7281, 1.381, 0.6623, 0...</td>\n",
       "      <td>[0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>id_00abef1d7</td>\n",
       "      <td>GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...</td>\n",
       "      <td>.........((((((((......((((((((((((....)))))))...</td>\n",
       "      <td>EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>2.485</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.422, 0.5478000000000001, 0.4749000000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...</td>\n",
       "      <td>[0.9306000000000001, 1.0496, 0.5844, 0.7796000...</td>\n",
       "      <td>[0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...</td>\n",
       "      <td>[0.46040000000000003, 3.6695, 0.78550000000000...</td>\n",
       "      <td>[2.7711, 7.365, 1.6924000000000001, 1.43840000...</td>\n",
       "      <td>[1.073, 2.8604000000000003, 1.9936, 1.0273, 1....</td>\n",
       "      <td>[2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>id_00b436dec</td>\n",
       "      <td>GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...</td>\n",
       "      <td>.....(((((((((((..(((((((((..((((....))))..)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...</td>\n",
       "      <td>1.727</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.4843, 0.5233, 0.4554, 0.43520000000000003, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.384, 0.723, 0.4766, 0.30260000000000004, 0....</td>\n",
       "      <td>[0.7429, 0.9137000000000001, 0.480400000000000...</td>\n",
       "      <td>[1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...</td>\n",
       "      <td>[1.6912, 5.2652, 2.3901, 0.45890000000000003, ...</td>\n",
       "      <td>[1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...</td>\n",
       "      <td>[0.49060000000000004, 4.6339, 1.95860000000000...</td>\n",
       "      <td>[1.2852000000000001, 2.5460000000000003, 0.234...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2394</td>\n",
       "      <td>id_ff13729b0</td>\n",
       "      <td>GGAAAUAAAUAAAUAACAAUAAAGAGAUAAGACACAAUAAAUAAAA...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...</td>\n",
       "      <td>1.995</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.3019, 0.33680000000000004, 0.25980000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25930000000000003, 0.3074, 0.2109, 0.1995, ...</td>\n",
       "      <td>[0.465, 0.6078, 0.30310000000000004, 0.3873000...</td>\n",
       "      <td>[0.3517, 0.5358, 0.4318, 0.016900000000000002,...</td>\n",
       "      <td>[0.6612, 1.0221, 0.1676, 0.1648, 0.5634, 0.645...</td>\n",
       "      <td>[4.0973, 2.0778, 0.2776, 0.1207, 0.63140000000...</td>\n",
       "      <td>[0.2661, 0.5771000000000001, 0.3517, 0.295, 0....</td>\n",
       "      <td>[0.2897, 1.1666, 0.135, 0.4742, 0.9522, 0.8408...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2395</td>\n",
       "      <td>id_ff84602f7</td>\n",
       "      <td>GGAAAAUAGCAGAGGAAAUACUAGAGCAAUUGCAAAGGCCGAUCAU...</td>\n",
       "      <td>........((..((......))...)).........(((..........</td>\n",
       "      <td>EEEEEEEESSIISSHHHHHHSSIIISSXXXXXXXXXSSSHHHHHHH...</td>\n",
       "      <td>4.036</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2585, 0.29710000000000003, 0.2748, 0.205000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2093, 0.2985, 0.2922, 0.08360000000000001, ...</td>\n",
       "      <td>[0.29460000000000003, 0.40850000000000003, 0.3...</td>\n",
       "      <td>[0.6957, 1.251, 1.3235999999999999, 0.7521, 0....</td>\n",
       "      <td>[0.6439, 2.0117, 1.3682, 0.0918, 0.65860000000...</td>\n",
       "      <td>[2.1589, 3.3601, 1.6179000000000001, 0.1344000...</td>\n",
       "      <td>[0.47900000000000004, 1.9583, 2.4635, 0.0512, ...</td>\n",
       "      <td>[0.5759000000000001, 2.3736, 1.4158, 0.1914000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2396</td>\n",
       "      <td>id_ff85fcdba</td>\n",
       "      <td>GGAAAACAAAAACAAACAACAAAAACAAACAACAAAAACAAACAAC...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...</td>\n",
       "      <td>3.227</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.2169, 0.2513, 0.2303, 0.22260000000000002, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2758, 0.3659, 0.2155, 0.28340000000000004, ...</td>\n",
       "      <td>[0.401, 0.388, 0.3403, 0.3608, 0.3057, 0.242, ...</td>\n",
       "      <td>[0.2891, 0.4496, 0.7165, 0.7128, 0.59310000000...</td>\n",
       "      <td>[0.3619, 0.6924, 0.2988, 0.3639, 0.545, 0.2263...</td>\n",
       "      <td>[2.8541, 1.6106, 1.4343, 1.0797, 0.6803, 0.559...</td>\n",
       "      <td>[0.2964, 0.9351, 0.2555, 0.7603000000000001, 0...</td>\n",
       "      <td>[0.6526000000000001, 0.2548, 0.6927, 0.9316000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>id_ffe06f3fe</td>\n",
       "      <td>GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...</td>\n",
       "      <td>.....((((..(....)..))))......(((....)))..........</td>\n",
       "      <td>EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...</td>\n",
       "      <td>5.553</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1431, 0.1847, 0.15960000000000002, 0.1466, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0944, 0.1453, 0.1067, 0.0994, 0.06470000000...</td>\n",
       "      <td>[0.1691, 0.22740000000000002, 0.178, 0.1762, 0...</td>\n",
       "      <td>[0.6919000000000001, 1.4823, 1.3685, 1.2473, 0...</td>\n",
       "      <td>[0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...</td>\n",
       "      <td>[2.7157999999999998, 3.1249000000000002, 1.137...</td>\n",
       "      <td>[0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...</td>\n",
       "      <td>[0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>id_fff546103</td>\n",
       "      <td>GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...</td>\n",
       "      <td>.....((((((((((((((((...)))).)))).((((((((((.....</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...</td>\n",
       "      <td>6.545</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1782, 0.2043, 0.1842, 0.13240000000000002, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.22060000000000002, 0.254, 0.2109, 0.1636, 0...</td>\n",
       "      <td>[0.2379, 0.27590000000000003, 0.22160000000000...</td>\n",
       "      <td>[1.0102, 1.7928000000000002, 1.9228, 0.9649000...</td>\n",
       "      <td>[1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...</td>\n",
       "      <td>[2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...</td>\n",
       "      <td>[1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...</td>\n",
       "      <td>[0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...</td>\n",
       "      <td>[[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...</td>\n",
       "      <td>[[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...</td>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2097 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index            id                                           sequence  \\\n",
       "0         0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "2         2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "5         5  id_00ab2d761  GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...   \n",
       "6         6  id_00abef1d7  GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...   \n",
       "7         7  id_00b436dec  GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...   \n",
       "...     ...           ...                                                ...   \n",
       "2394   2394  id_ff13729b0  GGAAAUAAAUAAAUAACAAUAAAGAGAUAAGACACAAUAAAUAAAA...   \n",
       "2395   2395  id_ff84602f7  GGAAAAUAGCAGAGGAAAUACUAGAGCAAUUGCAAAGGCCGAUCAU...   \n",
       "2396   2396  id_ff85fcdba  GGAAAACAAAAACAAACAACAAAAACAAACAACAAAAACAAACAAC...   \n",
       "2398   2398  id_ffe06f3fe  GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...   \n",
       "2399   2399  id_fff546103  GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...   \n",
       "\n",
       "                                              structure  \\\n",
       "0     .....((((((.......)))).)).((.....((..((((((......   \n",
       "2     .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "5     .....(.(((((.(((((((((...........)))))))..(((....   \n",
       "6     .........((((((((......((((((((((((....)))))))...   \n",
       "7     .....(((((((((((..(((((((((..((((....))))..)))...   \n",
       "...                                                 ...   \n",
       "2394  .................................................   \n",
       "2395  ........((..((......))...)).........(((..........   \n",
       "2396  .................................................   \n",
       "2398  .....((((..(....)..))))......(((....)))..........   \n",
       "2399  .....((((((((((((((((...)))).)))).((((((((((.....   \n",
       "\n",
       "                                    predicted_loop_type  signal_to_noise  \\\n",
       "0     EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "2     EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "5     EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...            4.136   \n",
       "6     EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...            2.485   \n",
       "7     EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...            1.727   \n",
       "...                                                 ...              ...   \n",
       "2394  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...            1.995   \n",
       "2395  EEEEEEEESSIISSHHHHHHSSIIISSXXXXXXXXXSSSHHHHHHH...            4.036   \n",
       "2396  EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE...            3.227   \n",
       "2398  EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...            5.553   \n",
       "2399  EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...            6.545   \n",
       "\n",
       "      SN_filter  seq_length  seq_scored  \\\n",
       "0             1         107          68   \n",
       "2             1         107          68   \n",
       "5             1         107          68   \n",
       "6             1         107          68   \n",
       "7             1         107          68   \n",
       "...         ...         ...         ...   \n",
       "2394          0         107          68   \n",
       "2395          1         107          68   \n",
       "2396          1         107          68   \n",
       "2398          0         107          68   \n",
       "2399          1         107          68   \n",
       "\n",
       "                                       reactivity_error  ...  \\\n",
       "0     [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  ...   \n",
       "2     [0.0931, 0.13290000000000002, 0.11280000000000...  ...   \n",
       "5     [0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...  ...   \n",
       "6     [0.422, 0.5478000000000001, 0.4749000000000000...  ...   \n",
       "7     [0.4843, 0.5233, 0.4554, 0.43520000000000003, ...  ...   \n",
       "...                                                 ...  ...   \n",
       "2394  [0.3019, 0.33680000000000004, 0.25980000000000...  ...   \n",
       "2395  [0.2585, 0.29710000000000003, 0.2748, 0.205000...  ...   \n",
       "2396  [0.2169, 0.2513, 0.2303, 0.22260000000000002, ...  ...   \n",
       "2398  [0.1431, 0.1847, 0.15960000000000002, 0.1466, ...  ...   \n",
       "2399  [0.1782, 0.2043, 0.1842, 0.13240000000000002, ...  ...   \n",
       "\n",
       "                                       deg_error_Mg_50C  \\\n",
       "0     [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "2     [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "5     [0.165, 0.20520000000000002, 0.179, 0.1333, 0....   \n",
       "6     [0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...   \n",
       "7     [0.384, 0.723, 0.4766, 0.30260000000000004, 0....   \n",
       "...                                                 ...   \n",
       "2394  [0.25930000000000003, 0.3074, 0.2109, 0.1995, ...   \n",
       "2395  [0.2093, 0.2985, 0.2922, 0.08360000000000001, ...   \n",
       "2396  [0.2758, 0.3659, 0.2155, 0.28340000000000004, ...   \n",
       "2398  [0.0944, 0.1453, 0.1067, 0.0994, 0.06470000000...   \n",
       "2399  [0.22060000000000002, 0.254, 0.2109, 0.1636, 0...   \n",
       "\n",
       "                                          deg_error_50C  \\\n",
       "0     [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "2     [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "5     [0.2864, 0.24710000000000001, 0.2222, 0.1903, ...   \n",
       "6     [0.9306000000000001, 1.0496, 0.5844, 0.7796000...   \n",
       "7     [0.7429, 0.9137000000000001, 0.480400000000000...   \n",
       "...                                                 ...   \n",
       "2394  [0.465, 0.6078, 0.30310000000000004, 0.3873000...   \n",
       "2395  [0.29460000000000003, 0.40850000000000003, 0.3...   \n",
       "2396  [0.401, 0.388, 0.3403, 0.3608, 0.3057, 0.242, ...   \n",
       "2398  [0.1691, 0.22740000000000002, 0.178, 0.1762, 0...   \n",
       "2399  [0.2379, 0.27590000000000003, 0.22160000000000...   \n",
       "\n",
       "                                             reactivity  \\\n",
       "0     [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "2     [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "5     [0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...   \n",
       "6     [0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...   \n",
       "7     [1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...   \n",
       "...                                                 ...   \n",
       "2394  [0.3517, 0.5358, 0.4318, 0.016900000000000002,...   \n",
       "2395  [0.6957, 1.251, 1.3235999999999999, 0.7521, 0....   \n",
       "2396  [0.2891, 0.4496, 0.7165, 0.7128, 0.59310000000...   \n",
       "2398  [0.6919000000000001, 1.4823, 1.3685, 1.2473, 0...   \n",
       "2399  [1.0102, 1.7928000000000002, 1.9228, 0.9649000...   \n",
       "\n",
       "                                            deg_Mg_pH10  \\\n",
       "0     [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "2     [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "5     [0.9559000000000001, 1.9442, 1.0114, 0.5105000...   \n",
       "6     [0.46040000000000003, 3.6695, 0.78550000000000...   \n",
       "7     [1.6912, 5.2652, 2.3901, 0.45890000000000003, ...   \n",
       "...                                                 ...   \n",
       "2394  [0.6612, 1.0221, 0.1676, 0.1648, 0.5634, 0.645...   \n",
       "2395  [0.6439, 2.0117, 1.3682, 0.0918, 0.65860000000...   \n",
       "2396  [0.3619, 0.6924, 0.2988, 0.3639, 0.545, 0.2263...   \n",
       "2398  [0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...   \n",
       "2399  [1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...   \n",
       "\n",
       "                                               deg_pH10  \\\n",
       "0     [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "2     [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "5     [1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...   \n",
       "6     [2.7711, 7.365, 1.6924000000000001, 1.43840000...   \n",
       "7     [1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...   \n",
       "...                                                 ...   \n",
       "2394  [4.0973, 2.0778, 0.2776, 0.1207, 0.63140000000...   \n",
       "2395  [2.1589, 3.3601, 1.6179000000000001, 0.1344000...   \n",
       "2396  [2.8541, 1.6106, 1.4343, 1.0797, 0.6803, 0.559...   \n",
       "2398  [2.7157999999999998, 3.1249000000000002, 1.137...   \n",
       "2399  [2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...   \n",
       "\n",
       "                                             deg_Mg_50C  \\\n",
       "0     [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "2     [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "5     [0.22460000000000002, 1.7281, 1.381, 0.6623, 0...   \n",
       "6     [1.073, 2.8604000000000003, 1.9936, 1.0273, 1....   \n",
       "7     [0.49060000000000004, 4.6339, 1.95860000000000...   \n",
       "...                                                 ...   \n",
       "2394  [0.2661, 0.5771000000000001, 0.3517, 0.295, 0....   \n",
       "2395  [0.47900000000000004, 1.9583, 2.4635, 0.0512, ...   \n",
       "2396  [0.2964, 0.9351, 0.2555, 0.7603000000000001, 0...   \n",
       "2398  [0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...   \n",
       "2399  [1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...   \n",
       "\n",
       "                                                deg_50C  \\\n",
       "0     [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...   \n",
       "2     [0.9501000000000001, 1.7974999999999999, 1.499...   \n",
       "5     [0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...   \n",
       "6     [2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...   \n",
       "7     [1.2852000000000001, 2.5460000000000003, 0.234...   \n",
       "...                                                 ...   \n",
       "2394  [0.2897, 1.1666, 0.135, 0.4742, 0.9522, 0.8408...   \n",
       "2395  [0.5759000000000001, 2.3736, 1.4158, 0.1914000...   \n",
       "2396  [0.6526000000000001, 0.2548, 0.6927, 0.9316000...   \n",
       "2398  [0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...   \n",
       "2399  [0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...   \n",
       "\n",
       "                                            One_hot seq  \\\n",
       "0     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "5     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "6     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "7     [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "...                                                 ...   \n",
       "2394  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2395  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2396  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2398  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "2399  [[[1, 0, 0, 0]], [[1, 0, 0, 0]], [[0, 1, 0, 0]...   \n",
       "\n",
       "                                       One hot strucure  \\\n",
       "0     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "5     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "6     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "7     [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "...                                                 ...   \n",
       "2394  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2395  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2396  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2398  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "2399  [[[1, 0, 0]], [[1, 0, 0]], [[1, 0, 0]], [[1, 0...   \n",
       "\n",
       "                                encoding predicted loop  \n",
       "0     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "5     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "6     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "7     [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2394  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2395  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2396  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2398  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "2399  [[[1, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2097 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encoding(df, name_colonne):\n",
    "    \"\"\"\n",
    "    Fonction pour encoder les sequences, structures et type boucles : One hot encoding\n",
    "        :Parameters:\n",
    "            df = data frame : train et test de départ\n",
    "            name_colonne = le nom de la colonne du df \n",
    "        :Return:\n",
    "            un tableau\n",
    "    \"\"\"\n",
    "    frst_lst = []\n",
    "    for r in df[name_colonne]:\n",
    "        for i in range(len(r)):\n",
    "            if r[i] not in frst_lst:\n",
    "                frst_lst.append(r[i])\n",
    "    dico = {}\n",
    "    ar = np.zeros(shape=(1,len(frst_lst)),dtype=int)\n",
    "    for i, l in enumerate(frst_lst):\n",
    "        ar2 = ar.copy()\n",
    "        ar2[0][i]=1\n",
    "        dico[l]=ar2\n",
    "    scnd_lst = []\n",
    "    for r in df[name_colonne]:\n",
    "        lst = [] \n",
    "        for i in range(len(r)):\n",
    "            #print(dico[r[i]], r[i])\n",
    "            lst.append(dico[r[i]])\n",
    "        scnd_lst.append(lst)\n",
    "    return np.array(scnd_lst)\n",
    "\n",
    "tab = one_hot_encoding(first68_train, 'sequence')\n",
    "tab2 = one_hot_encoding(first68_train, 'structure')\n",
    "tab3 = one_hot_encoding(first68_train, 'predicted_loop_type')\n",
    "\n",
    "first68_train[\"One_hot seq\"] = tab.tolist() # ajout des colonnes encoding a notre DF de départ\n",
    "first68_train[\"One hot strucure\"] = tab2.tolist()\n",
    "first68_train[\"encoding predicted loop\"] = tab3.tolist()\n",
    "first68_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_format(df, colname):\n",
    "    \"\"\"\n",
    "    juste pck j'crois que y'avait des liste dans des listes\n",
    "    j'ai transformé en liste d'array\n",
    "    \"\"\"\n",
    "    x1 = df[colname].copy()\n",
    "    x2 = []\n",
    "    for r in x1:\n",
    "        lst = []\n",
    "        for u in r:\n",
    "            lst.append(np.array(u[0], float))\n",
    "        lst = np.array(lst)\n",
    "        x2.append(lst)\n",
    "\n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097, 68, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = right_format(first68_train, \"One_hot seq\")\n",
    "x_strct = right_format(first68_train, \"One hot strucure\")\n",
    "x_loop = right_format(first68_train, \"encoding predicted loop\")\n",
    "\n",
    "#print(len(x_seq))\n",
    "#print(len(x_strct))\n",
    "#print(len(x_loop))\n",
    "x_seq = np.array(x_seq)\n",
    "x_strct = np.array(x_strct)\n",
    "x_loop = np.array(x_loop)\n",
    "x_all = np.concatenate((x_seq, x_strct,x_loop), axis=2)\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.random.normal((32, 68, 5))\n",
    "y_pred = tf.random.normal((32, 68, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    re = tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    print(re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.GRU(\n",
    "        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))\n",
    "\n",
    "def build_model(embed_size, seq_len=68, pred_len=68, dropout=0.5, \n",
    "                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=1):\n",
    "    inputs = L.Input(shape=(seq_len, 14))# 107 longueur sequence - 4 ATGU\n",
    "    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n",
    "\n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, 68,  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n",
    "    \n",
    "    for x in range(n_layers):\n",
    "        print(x,\"layer\")\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    # Since we are only making predictions on the first part of each sequence, \n",
    "    # we have to truncate it\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    out = L.Dense(5, activation='linear')(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    model.compile(tf.keras.optimizers.RMSprop(), loss=MCRMSE, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pandas_list_to_array(train[pred_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1887, 68, 14)\n",
      "(1887, 68, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_all, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 layer\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 68, 14)]          0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 68, 14, 200)       800       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (Tenso [(None, 68, 2800)]        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 68, 2800)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 68, 512)           4697088   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_1  [(None, 68, 512)]         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 68, 5)             2565      \n",
      "=================================================================\n",
      "Total params: 4,700,453\n",
      "Trainable params: 4,700,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(embed_size=4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"MCRMSE/Mean_1:0\", shape=(None,), dtype=float32)\n",
      "17/30 [================>.............] - ETA: 45s - loss: 0.6481 - accuracy: 0.2206"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-00ef26481ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=75,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n",
    "        tf.keras.callbacks.ModelCheckpoint('model.h5')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(\n",
    "    history.history, y=['loss', 'accuracy', 'val_loss', 'val_accuracy'],\n",
    "    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n",
    "    title='Training History')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
